{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forests.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVYN4sBXSTn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNvF2QAN7_Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mckrzy1HSWTz",
        "colab_type": "code",
        "outputId": "c6dfe62c-27b2-4b15-812f-542026134526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  3 09:51:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLJamFchODGJ",
        "colab_type": "code",
        "outputId": "dbb8bc48-9b3c-46ce-cbe6-868b2567343b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from hyperopt import hp\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import cross_validate\n",
        "from collections import Counter\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "pd.set_option('display.max_columns',None)\n",
        "pd.set_option('display.max_rows',None)\n",
        "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU3O0MNFOJQ-",
        "colab_type": "code",
        "outputId": "5bd353bb-9171-464f-e00a-e0bca6542760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "data = pd.read_csv('/content/drive/My Drive/Data/features.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'].apply(lambda x: x.split()[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.25 s, sys: 444 ms, total: 5.7 s\n",
            "Wall time: 7.14 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEi5_JVSOPNi",
        "colab_type": "code",
        "outputId": "d5b7fc15-79d1-4c7d-e686-c308932b28bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "for key in data.columns:\n",
        "    if 'Days' in key:\n",
        "        data[key] = data[key].apply(round)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 424 ms, sys: 46 ms, total: 470 ms\n",
            "Wall time: 470 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOH33BrJOSaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sel = ['Amount_Cardnum_sum_0d',\n",
        " 'Cardnum_count_0d',\n",
        " 'Amount_Cardnum_sum_1d',\n",
        " 'Amount_Merchnum_mean_0d',\n",
        " 'Amount_Merchnum_max_0d',\n",
        " 'Amount_Merchnum_sum_0d',\n",
        " 'Amount_Merchnum_max_1d',\n",
        " 'Amount_Cardnum_Merchnum_max_0d',\n",
        " 'Amount_Cardnum_Merch zip_sum_0d',\n",
        " 'Amount_Cardnum_Merch zip_max_3d',\n",
        " 'Amount_Cardnum_Merch zip_sum_3d',\n",
        " 'Cardnum_Merch zip_count_3d',\n",
        " 'Amount_Cardnum_Merch zip_sum_7d',\n",
        " 'Cardnum_Merch zip_count_7d',\n",
        " 'Amount_Cardnum_Merch zip_max_14d',\n",
        " 'Amount_Cardnum_Merch zip_sum_14d',\n",
        " 'Cardnum_Merch zip_count_14d',\n",
        " 'Amount_Cardnum_Merch zip_max_30d',\n",
        " 'Amount_Cardnum_Merch zip_sum_30d',\n",
        " 'Amount_Cardnum_Merch state_max_1d',\n",
        " 'Amount_Cardnum_Merch state_max_3d',\n",
        " 'Amount_Cardnum_Merch state_sum_3d',\n",
        " 'Amount_Cardnum_Merch state_max_7d',\n",
        " 'count_Cardnum_0d/mean_mean_Cardnum_14d',\n",
        " 'count_Cardnum_0d/mean_mean_Cardnum_30d',\n",
        " 'count_Cardnum_0d/mean_count_Cardnum_30d',\n",
        " 'count_Cardnum_1d/mean_mean_Cardnum_30d',\n",
        " 'count_Cardnum_1d/mean_count_Cardnum_30d',\n",
        " 'count_Merchnum_0d/mean_count_Merchnum_7d',\n",
        " 'count_Merchnum_0d/mean_count_Merchnum_14d']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c28eBzjLOWMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[sel + ['Date', 'Fraud']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJx9Qw5nOZcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data['Date'] > pd.to_datetime('2010-01-14')]\n",
        "train = data[data['Date'] <= pd.to_datetime('2010-10-31')].copy()\n",
        "test = data[data['Date'] > pd.to_datetime('2010-10-31')].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoFZxOy8Obuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = train_test_split(train, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBcqTPeDOdlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.drop(columns = ['Date', 'Fraud'])\n",
        "y = train['Fraud']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0GefB3jSwZB",
        "colab_type": "code",
        "outputId": "1b07355f-c152-46c8-bfa7-467d160188db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Counter(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 63833, 1: 672})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUwYin7Of7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_fdr(y_true, y_pred):\n",
        "    tot = y_true.sum()\n",
        "    pos = y_true[y_pred.argsort()[::-1]][:int(len(y_true) * 0.03)].sum()\n",
        "    return pos / tot *100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEwcdCSHOu3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fdr_scorer = make_scorer(calculate_fdr, needs_proba = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mMw3sJkO8KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rf_score(params):\n",
        "    selector = SelectFromModel(estimator=xgb.XGBRFClassifier(tree_method = 'gpu_hist'), max_features = params['max_features']).fit(X, y)\n",
        "    del params['max_features']\n",
        "    X_best = selector.transform(X)\n",
        "    resampler = SMOTETomek(sampling_strategy = params['sampling_strategy'])\n",
        "    X_best, y_best = resampler.fit_resample(X_best, y)\n",
        "    del params['sampling_strategy']\n",
        "    fdr = np.mean(cross_validate(xgb.XGBRFClassifier(**params), X_best, y_best.values, scoring = fdr_scorer, cv = TimeSeriesSplit(n_splits = 5))['test_score'])\n",
        "    return {'loss': -1 * fdr, 'status': STATUS_OK}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R00U0BPlPDUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rf_optimize(evals, trials, optimizer=tpe.suggest, random_state=0):\n",
        "    space = {\n",
        "        'sampling_strategy': hp.quniform('sampling_strategy', 0.015, 0.05, 0.01),\n",
        "        'max_features': hp.choice('max_features', np.arange(5, 30, dtype=int)),\n",
        "        'n_estimators': hp.choice('n_estimators', np.arange(200, 600, dtype=int)),\n",
        "        'scale_pos_weight': hp.quniform('scale_pos_weight', 0, 1, 0.01),\n",
        "        'eta': hp.quniform('eta', 0.025, 0.25, 0.025),\n",
        "        'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
        "        'min_child_weight': hp.quniform('min_child_weight', 1, 100, 1),\n",
        "        'subsample': hp.quniform('subsample', 0.7, 1, 0.05),\n",
        "        'gamma': hp.quniform('gamma', 0.5, 10, 0.05),\n",
        "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
        "        'alpha' :  hp.quniform('alpha', 0, 10, 1),\n",
        "        'lambda': hp.quniform('lambda', 1, 2, 0.1),\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'seed': random_state\n",
        "    }\n",
        "    best = fmin(rf_score, space, algo=tpe.suggest, max_evals=evals, trials = trials, rstate =  np.random.RandomState(0))\n",
        "    return best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlXmidf-PE49",
        "colab_type": "code",
        "outputId": "88afc456-bd00-4d97-b774-76928fea0070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%%time\n",
        "trials = Trials()\n",
        "n= 500\n",
        "rf_best_param = rf_optimize(evals = n,\n",
        "                      optimizer=tpe.suggest,\n",
        "                      trials = trials)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [44:53<00:00,  5.39s/it, best loss: -71.45367884496349]\n",
            "CPU times: user 33min 16s, sys: 11min 41s, total: 44min 57s\n",
            "Wall time: 44min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDpYiuroPPO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_best_param['tree_method'] = 'gpu_hist'\n",
        "rf_best_param['max_features'] = np.arange(5, 30, dtype=int)[rf_best_param['max_features']]\n",
        "rf_best_param['n_estimators'] = np.arange(200, 600, dtype=int)[rf_best_param['n_estimators']]\n",
        "rf_best_param['seed'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqgtv3jHQEjz",
        "colab_type": "code",
        "outputId": "da2ef56c-a273-4476-c971-fc0361bf0511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "rf_best_param"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 2.0,\n",
              " 'colsample_bytree': 0.8,\n",
              " 'eta': 0.07500000000000001,\n",
              " 'gamma': 2.2,\n",
              " 'lambda': 1.9000000000000001,\n",
              " 'max_depth': 9,\n",
              " 'max_features': 17,\n",
              " 'min_child_weight': 1.0,\n",
              " 'n_estimators': 553,\n",
              " 'sampling_strategy': 0.02,\n",
              " 'scale_pos_weight': 0.75,\n",
              " 'seed': 0,\n",
              " 'subsample': 0.8,\n",
              " 'tree_method': 'gpu_hist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_a-WLVW441",
        "colab_type": "code",
        "outputId": "36df25e8-0f76-4505-ad33-b19642349ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "selector = SelectFromModel(estimator=xgb.XGBClassifier(tree_method = 'gpu_hist'), max_features = rf_best_param['max_features'])\n",
        "X_best = selector.fit_transform(X, y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 248 ms, sys: 101 ms, total: 349 ms\n",
            "Wall time: 349 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0VRjBybXMH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del rf_best_param['max_features']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvSRPcxkkPfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resampler = SMOTETomek(sampling_strategy = rf_best_param['sampling_strategy'])\n",
        "X_best, y_best = resampler.fit_resample(X_best, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Icun_DpkP20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del rf_best_param['sampling_strategy']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCLYhVuQ_t7",
        "colab_type": "code",
        "outputId": "6f9cc3f7-e271-4182-cc01-05557bec2115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "model = xgb.XGBRFClassifier(**rf_best_param)\n",
        "model.fit(X_best, y_best)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.59 s, sys: 733 ms, total: 4.32 s\n",
            "Wall time: 4.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Dd2r27RHoO",
        "colab_type": "code",
        "outputId": "d3cf0109-0773-4c1f-843c-40ebc53635f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calculate_fdr(train['Fraud'].values, model.predict_proba(selector.transform(train.drop(columns = ['Date', 'Fraud'])))[:,1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.72619047619048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q8cY2JV0X4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Fraud_score'] = model.predict_proba(selector.transform(train.drop(columns = ['Date', 'Fraud'])))[:,1]\n",
        "train[['Fraud', 'Fraud_score']].sort_values(by = 'Fraud_score', ascending = False).to_csv('/content/drive/My Drive/Data/random_forest_train_fraud_scores.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQUn7Oz-R2eI",
        "colab_type": "code",
        "outputId": "53889368-fe3b-4ae4-9646-96fad5293052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calculate_fdr(val['Fraud'].values, model.predict_proba(selector.transform(val.drop(columns = ['Date', 'Fraud'])))[:,1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.36734693877551"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70jFBUWf0YqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val['Fraud_score'] = model.predict_proba(selector.transform(val.drop(columns = ['Date', 'Fraud'])))[:,1]\n",
        "val[['Fraud', 'Fraud_score']].sort_values(by = 'Fraud_score', ascending = False).to_csv('/content/drive/My Drive/Data/random_forest_test_fraud_scores.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBaIvxdLRRWC",
        "colab_type": "code",
        "outputId": "b2441d65-a68d-4ab0-f7de-3c19b0b46f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calculate_fdr(test['Fraud'].values, model.predict_proba(selector.transform(test.drop(columns = ['Date', 'Fraud'])))[:,1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.072625698324025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGzJrCyG0ZnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['Fraud_score'] = model.predict_proba(selector.transform(test.drop(columns = ['Date', 'Fraud'])))[:,1]\n",
        "test[['Fraud', 'Fraud_score']].sort_values(by = 'Fraud_score', ascending = False).to_csv('/content/drive/My Drive/Data/random_forest_oot_fraud_scores.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}