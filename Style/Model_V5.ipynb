{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_V5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYLh03fo9dKgHA+3ihfQQj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLHOmMukGGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pxdph9JB-dG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a7489db8-46ad-488f-89ec-8a35f8c89952"
      },
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
            "\r\u001b[K     |██                              | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 34.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 36.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 37.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 38.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 38.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 38.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 38.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122kB 38.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133kB 38.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143kB 38.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 153kB 38.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZMWoVO4kknG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "522c994a-f433-4ef8-ea2e-0c9597dd06d4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential \n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense, Input, Reshape\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import Dense, GlobalAveragePooling1D, Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "import keras.backend as K \n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models.phrases import Phraser, Phrases"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J88vxQgkvZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d0ceb7a7-95b1-4779-b85f-3ca4d8697028"
      },
      "source": [
        "%%time\n",
        "df = pd.read_csv('/content/drive/Shared drives/DSO 560 NLP Project/data.csv')\n",
        "df = df[df['attribute_name'] == 'style'].drop(columns = ['attribute_name'])\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'businesscasual' if x == 'business casual' else x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 280 ms, sys: 53.3 ms, total: 334 ms\n",
            "Wall time: 358 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyu18_culshy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "740878ca-69c1-4f96-d6dd-a4e3cab464da"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
              "      <td>frame</td>\n",
              "      <td>les second medium noir</td>\n",
              "      <td>minimal , modern styling meet refined luxury l...</td>\n",
              "      <td>accessory</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>01DPH1DEN9G2WM7WAMJMD0A9W4</td>\n",
              "      <td>j crew</td>\n",
              "      <td>tie waist shirtdress stripe</td>\n",
              "      <td>take classic button silhouette turn ultra flat...</td>\n",
              "      <td>dressesandjumpsuits</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>01E2KYW52BAG606GQ7A9H5R0KD</td>\n",
              "      <td>alo</td>\n",
              "      <td>interval microfleece pullover hoodie</td>\n",
              "      <td>articulate seam extra wide rib hem create shap...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>01DT513RRYT3SKH6X25G5VCH6B</td>\n",
              "      <td>chlo</td>\n",
              "      <td>leather ankle boot</td>\n",
              "      <td>heel measure approximately 55 mm 2 inch 30 mm ...</td>\n",
              "      <td>shoe boots ankle</td>\n",
              "      <td>androgynous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>01E2KM0KW6NB1JKMZVRXR6H8G2</td>\n",
              "      <td>alo</td>\n",
              "      <td>stadium quarter zip hoodie</td>\n",
              "      <td>supersoft hoodie design elastic hem cuff perfe...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    product_id   brand  ...       brand_category attribute_value\n",
              "0   01DPGV4YRP3Z8J85DASGZ1Y99W   frame  ...            accessory          casual\n",
              "5   01DPH1DEN9G2WM7WAMJMD0A9W4  j crew  ...  dressesandjumpsuits          casual\n",
              "12  01E2KYW52BAG606GQ7A9H5R0KD     alo  ...              unknown          casual\n",
              "13  01DT513RRYT3SKH6X25G5VCH6B    chlo  ...     shoe boots ankle     androgynous\n",
              "20  01E2KM0KW6NB1JKMZVRXR6H8G2     alo  ...              unknown          casual\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KCfa3CVn9nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category']).apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMi2ULgelhFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['text'].values\n",
        "y = pd.get_dummies(df['attribute_value']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YFmF01NwQGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_1gram(X, mode = 'binary'):\n",
        "    tokenizer = Tokenizer(num_words=500)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "    length = max([len(s.split()) for s in df['text']])\n",
        "    X = tokenizer.texts_to_matrix(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    return X, length, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oETme721eAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_2gram(X, mode='binary'):\n",
        "    phrases = Phrases(X, min_count=30)\n",
        "    bigrams = Phraser(phrases)\n",
        "    X = list(bigrams[X])\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=500)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "    length = max([len(s.split()) for s in df['text']])\n",
        "    X = tokenizer.texts_to_matrix(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    return X, length, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30eS_YrlwyL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b84530f8-b367-4fd0-bd99-47df41a323de"
      },
      "source": [
        "Tokenizer()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7fad5e50a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oEaE9mamM7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1, length1, vocab_size1 = encode_1gram(X, mode = 'tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGFzNuUUxWmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2, length2, vocab_size2 = encode_2gram(X, mode = 'tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM7aXsN--SXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X1 = X1.reshape(-1, 155, 1)\n",
        "#X2 = X2.reshape(-1, 155, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJpzT_ygA7Pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7c9e3dd-d50e-4985-f579-81fbcb576a95"
      },
      "source": [
        "X1.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10887, 155)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf8Gl0NGA1HV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate([X1, X2], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae88zjZ9CZye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDwRtJkSBvxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNTeR6ZRoxcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xgZ_gpen5wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model():\n",
        "    inputs = Input(shape=(length1+length2,))\n",
        "    #x1 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs1)\n",
        "    #embedding1 = Embedding(input_dim=vocab_size1, output_dim=100)(inputs1)\n",
        "\n",
        "    #inputs2 = Input(shape=(length2,))\n",
        "    #x2 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs2)\n",
        "    #dense2 = Dense(100, activation='relu')(inputs2)\n",
        "    #embedding2 = Embedding(input_dim=vocab_size2, output_dim=100)(inputs2)\n",
        "\n",
        "    #merged = concatenate([inputs1, inputs1])\n",
        "    #x = LSTM(16, return_sequences=False, dropout=0.2, recurrent_dropout=0.15)(merged)\n",
        "\n",
        "    x = Dense(100, activation = 'relu')(inputs)\n",
        "\n",
        "\n",
        "    #x = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(x)\n",
        "    #x = Conv1D(filters=num_classes, kernel_size=155, padding='valid')(x)\n",
        "    #x = Reshape((num_classes,))(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "    out = Activation('sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs = [inputs], outputs = out)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtVkDeU4pOFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = define_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfeN4H1XpRvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH0rgY1WChE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ythmDKKlpjsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(model.predict(X).argmax(axis = -1)).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjn1GCho_snJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WsQqrmxprsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(y.argmax(axis = -1)).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmfNQQbrqhhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}